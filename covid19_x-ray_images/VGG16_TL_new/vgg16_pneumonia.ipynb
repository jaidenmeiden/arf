{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-d8d2819827f2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mclassification_report\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mconfusion_matrix\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mimutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpaths\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mshutil\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrandom\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\desarrollo\\arf\\covid19_x-ray_images\\venv\\lib\\site-packages\\imutils\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# import the necessary packages\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mconvenience\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtranslate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mconvenience\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrotate\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mconvenience\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mrotate_bound\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\desarrollo\\arf\\covid19_x-ray_images\\venv\\lib\\site-packages\\imutils\\convenience.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# import the necessary packages\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf dataset\n",
    "mkdir -p dataset/covid\n",
    "mkdir -p dataset/normal\n",
    "mkdir -p dataset/pneumonia\n",
    "mkdir -p dataset/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_19_path = \"../DataSet2/covid-chest-xray\"\n",
    "pneumonia_dataset_path ='../DataSet2/chest-xray-pneumonia/chest_xray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = pd.read_csv('../DataSet2/covid-chest-xray/metadata.csv')\n",
    "\n",
    "\n",
    "sns.countplot(x = 'finding', data = eda, palette = 'husl')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'sex', data = eda, palette = 'husl')\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the path to the metadata CSV file and load it\n",
    "csvPath = os.path.sep.join([covid_19_path, \"metadata.csv\"])\n",
    "df = pd.read_csv(csvPath)\n",
    "\n",
    "# loop over the rows of the COVID-19 data frame\n",
    "for (i, row) in df.iterrows():\n",
    "    # if (1) the current case is not COVID-19 or (2) this is not\n",
    "    # a 'PA' view, then ignore the row\n",
    "    if row[\"finding\"] != \"COVID-19\" or row[\"view\"] != \"PA\":\n",
    "        continue\n",
    "\n",
    "    # build the path to the input image file\n",
    "    imagePath = os.path.sep.join([covid_19_path, \"images\", row[\"filename\"]])\n",
    "\n",
    "    # if the input image file does not exist (there are some errors in\n",
    "    # the COVID-19 metadeta file), ignore the row\n",
    "    if not os.path.exists(imagePath):\n",
    "        continue\n",
    "\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = row[\"filename\"].split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/covid\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"NORMAL\"])\n",
    "imagePaths = list(paths.list_images(basePath))\n",
    "samples = 146\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:samples]\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/normal\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.sep.join([pneumonia_dataset_path, \"train\", \"PNEUMONIA\"])\n",
    "imagePaths = list(paths.list_images(basePath))\n",
    "samples = 146\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:samples]\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/pneumonia\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-ray show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceildiv(a, b):\n",
    "    return -(-a // b)\n",
    "\n",
    "def plots_from_files(imspaths, figsize=(10,5), rows=1, titles=None, maintitle=None):\n",
    "    \"\"\"Plot the images in a grid\"\"\"\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    if maintitle is not None: plt.suptitle(maintitle, fontsize=10)\n",
    "    for i in range(len(imspaths)):\n",
    "        sp = f.add_subplot(rows, ceildiv(len(imspaths), rows), i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None: sp.set_title(titles[i], fontsize=16)\n",
    "        img = plt.imread(imspaths[i])\n",
    "        plt.imshow(img)\n",
    "\n",
    "normal_images = list(paths.list_images(f\"{dataset_path}/normal\"))\n",
    "covid_images = list(paths.list_images(f\"{dataset_path}/covid\"))\n",
    "pneumonia_images = list(paths.list_images(f\"{dataset_path}/pneumonia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_from_files(normal_images, rows=5, maintitle=\"Normal X-ray images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_from_files(covid_images, rows=5, maintitle=\"Covid-19 X-ray images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_from_files(pneumonia_images, rows=5, maintitle=\"Pneumonia X-ray images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take the labels of each image in the directory to make a classfication\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "data = []\n",
    "labels = []\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "# convert the data and labels to NumPy arrays while scaling the pixel\n",
    "# intensities to the range [0, 1]\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] Images successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a One-Hot encoding to the list of labels to make the classfication\n",
    "# integer encode\n",
    "lb_encoder = LabelEncoder()\n",
    "labels = lb_encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "\n",
    "# Split the data into training and testing using the 80% of training and 20% to testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size = 0.2, stratify = labels,random_state = 42)\n",
    "\n",
    "\n",
    "# Set the image augmentation of the training data\n",
    "trainAug = ImageDataGenerator(rotation_range= 15, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights = 'imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
    "headmodel = base_model.output\n",
    "headmodel = AveragePooling2D(pool_size =(4, 4))(headmodel)\n",
    "headmodel = Flatten(name ='Flatten')(headmodel)\n",
    "headmodel = Dense(64, activation = 'relu')(headmodel)\n",
    "headmodel = Dropout(0.5)(headmodel)\n",
    "headmodel = Dense(3, activation = 'softmax')(headmodel)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = headmodel)\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "\n",
    "opt = Adam(lr = INIT_LR, decay = INIT_LR/EPOCHS)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model with gpu or cpu, it depends:\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    print(\"Training the model with gpu . . .\")\n",
    "    training = model.fit_generator(trainAug.flow(X_train, y_train, batch_size = BS),steps_per_epoch=len(X_train) // BS, validation_data=(X_test, y_test), validation_steps=len(X_test) // BS, epochs=100)\n",
    "\n",
    "#with tf.device('/cpu:0'):\n",
    "#    print(\"Training the model with cpu . . .\")\n",
    "#    training = model.fit_generator(trainAug.flow(X_train, y_train, batch_size = BS),steps_per_epoch=len(X_train) // BS, validation_data=(X_test, y_test), validation_steps=len(X_test) // BS, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use('ggplot')\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), training.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), training.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), training.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), training.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy for Classification between COVID-19/Pneumonia/Normal\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1))\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(X_test, batch_size=BS)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(y_test.argmax(axis=1), predIdxs, target_names=lb_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the confusion matrix and and use it to derive the raw\n",
    "# accuracy, sensitivity, and specificity\n",
    "cm = confusion_matrix(y_test.argmax(axis=1), predIdxs)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "# show the accuracy, sensitivity, and specificity of the test\n",
    "print(\"accuracy: {:.4f}\".format(acc))\n",
    "print(\"sensitivity: {:.4f}\".format(sensitivity))\n",
    "print(\"specificity: {:.4f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm= pd.DataFrame(cm, columns=lb_encoder.classes_, index=lb_encoder.classes_)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm/np.sum(df_cm), fmt='.2%', annot = True, annot_kws={'size':16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10\n",
    "columns = 9\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for m in range(1, 88):\n",
    "    if str(lb_encoder.inverse_transform(predIdxs)[m-1]) == \"covid\":\n",
    "        text = \"COVID\"\n",
    "        color = (0, 255, 0)\n",
    "    elif str(lb_encoder.inverse_transform(predIdxs)[m-1]) == \"normal\":\n",
    "        text = \"Normal\"\n",
    "        color = (255, 0, 0)\n",
    "    elif str(lb_encoder.inverse_transform(predIdxs)[m-1]) == \"pneumonia\":\n",
    "        text = \"Pneumonia\"\n",
    "        color = (0, 0, 255)\n",
    "        \n",
    "    if str(lb_encoder.inverse_transform(y_test.argmax(axis=1))[m-1]) == \"covid\":\n",
    "        text2 = \"COVID\"\n",
    "        color2 = (0, 255, 0)\n",
    "    elif str(lb_encoder.inverse_transform(y_test.argmax(axis=1))[m-1]) == \"normal\":\n",
    "        text2 = \"Normal\"\n",
    "        color2 = (255, 0, 0)\n",
    "    elif str(lb_encoder.inverse_transform(y_test.argmax(axis=1))[m-1]) == \"pneumonia\":\n",
    "        text2 = \"Pneumonia\"\n",
    "        color2 = (0, 0, 255)\n",
    "    img = X_test[m-1].copy()\n",
    "    # Window name in which image is displayed \n",
    "    window_name = text\n",
    "  \n",
    "    # font \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    # org \n",
    "    org = (50, 50) \n",
    "  \n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "  \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    img = cv2.putText(img, text, org, font,\n",
    "                      fontScale, color, thickness, cv2.LINE_AA)\n",
    "    fig.add_subplot(rows, columns, m)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Actual: \" + text2)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with new images in different database (\"covid19-radiography-database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset ='../DataSet2/covid19-radiography-database/COVID-19 Radiography Database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = os.path.sep.join([new_dataset, \"Viral Pneumonia\"])\n",
    "imagePaths = list(paths.list_images(basePath))\n",
    "samples = 3\n",
    "\n",
    "# randomly sample the image paths\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "imagePaths = imagePaths[:samples]\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the filename from the image path and then construct the\n",
    "    # path to the copied image file\n",
    "    filename = imagePath.split(os.path.sep)[-1]\n",
    "    outputPath = os.path.sep.join([f\"{dataset_path}/new\", filename])\n",
    "\n",
    "    # copy the image\n",
    "    shutil.copy2(imagePath, outputPath)\n",
    "\n",
    "new_images = list(paths.list_images(f\"{dataset_path}/new\"))\n",
    "plots_from_files(new_images, rows=3, maintitle=\"New X-ray images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for imagePath in imagePaths:\n",
    "    new_image = cv2.imread(imagePath)\n",
    "    new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)\n",
    "    new_image = cv2.resize(new_image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    new_data.append(new_image)\n",
    "\n",
    "new_data = np.array(new_data) / 255.0\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new predictions:\n",
    "print(\"[INFO] Making new predictions...\")\n",
    "new_pred = model.predict(new_data, batch_size=BS)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "new_pred = np.argmax(new_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] printing new images with their classification\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for m in range(1, 4):\n",
    "    if str(lb_encoder.inverse_transform(new_pred)[m-1]) == \"covid\":\n",
    "        text = \"COVID\"\n",
    "        color = (0, 255, 0)\n",
    "    elif str(lb_encoder.inverse_transform(new_pred)[m-1]) == \"normal\":\n",
    "        text = \"Normal\"\n",
    "        color = (255, 0, 0)\n",
    "    elif str(lb_encoder.inverse_transform(new_pred)[m-1]) == \"pneumonia\":\n",
    "        text = \"Pneumonia\"\n",
    "        color = (0, 0, 255)\n",
    "    img = X_test[m-1].copy()\n",
    "    # Window name in which image is displayed \n",
    "    window_name = text\n",
    "  \n",
    "    # font \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    # org \n",
    "    org = (50, 50) \n",
    "  \n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "  \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    img = cv2.putText(img, text, org, font,\n",
    "                      fontScale, color, thickness, cv2.LINE_AA)\n",
    "    fig.add_subplot(rows, columns, m)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2 = []\n",
    "\n",
    "# Making some new testing for a specific image in the file:\n",
    "new_imag2 = cv2.imread('../DataSet2/covid19-radiography-database/COVID-19 Radiography Database/COVID-19/COVID-19 (10).png')\n",
    "new_imag2 = cv2.cvtColor(new_imag2, cv2.COLOR_BGR2RGB)\n",
    "new_imag2 = cv2.resize(new_imag2, (224,224))\n",
    "new_data2.append(new_imag2)\n",
    "\n",
    "new_data2 = np.array(new_data2)/255.0\n",
    "\n",
    "# make new prediction\n",
    "print(\"[INFO] Making new prediction...\")\n",
    "new_pred2 = model.predict(new_data2, batch_size=BS)\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "new_pred2 = np.argmax(new_pred2, axis=1)\n",
    "\n",
    "print(\"[INFO] printing new image with its classification\")\n",
    "rows = 1\n",
    "columns = 3\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for m in range(1, 2):\n",
    "    if str(lb_encoder.inverse_transform(new_pred2)[m-1]) == \"covid\":\n",
    "        text = \"COVID\"\n",
    "        color = (0, 255, 0)\n",
    "    elif str(lb_encoder.inverse_transform(new_pred2)[m-1]) == \"normal\":\n",
    "        text = \"Normal\"\n",
    "        color = (255, 0, 0)\n",
    "    elif str(lb_encoder.inverse_transform(new_pred2)[m-1]) == \"pneumonia\":\n",
    "        text = \"Pneumonia\"\n",
    "        color = (0, 0, 255)\n",
    "    img = X_test[m-1].copy()\n",
    "    # Window name in which image is displayed \n",
    "    window_name = text\n",
    "  \n",
    "    # font \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    # org \n",
    "    org = (50, 50) \n",
    "  \n",
    "    # fontScale \n",
    "    fontScale = 1\n",
    "  \n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    img = cv2.putText(img, text, org, font,\n",
    "                      fontScale, color, thickness, cv2.LINE_AA)\n",
    "    fig.add_subplot(rows, columns, m)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}